{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing traning data sets from live camera "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**By Ahmed Hammad**\n",
    "**ahammad115566@gmail.com**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import time \n",
    "def generate_data():\n",
    "    face_classifier = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "    def face_cropped(img):\n",
    "        gray_img = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "        faces_cropped = face_classifier.detectMultiScale(gray_img,1.3,6)\n",
    "        if face_cropped ==():\n",
    "            return None \n",
    "        for (x,y,w,h) in faces_cropped:\n",
    "            cropped_faces = img[y:y+h,x:x+w]\n",
    "            return cropped_faces\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    img_id = 0\n",
    "    while True :\n",
    "        ret, frame = cap.read()\n",
    "        if face_cropped(frame) is not None:\n",
    "            time.sleep(0.1)\n",
    "            img_id+=1\n",
    "            face= cv2.resize(face_cropped(frame),(500,500))\n",
    "            face=cv2.cvtColor(face,cv2.COLOR_BGR2GRAY)\n",
    "            file_path= \"pix/Ahmed/\"+'Ahmed.'+str(img_id)+'.jpg'\n",
    "            cv2.imwrite(file_path,face)\n",
    "            cv2.putText(face,'Id='+str(img_id),(50,50),cv2.FONT_HERSHEY_SIMPLEX,1,(0,0,255),3)\n",
    "            cv2.imshow('cropped face', face)\n",
    "            #cv2.waitKey(0)\n",
    "            if cv2.waitKey(1) & int(img_id) == 500:\n",
    "                break\n",
    "    \n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    cv2.waitKey(1)\n",
    "    print('preparing the data set completed....')\n",
    "        \n",
    "generate_data()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate labels from the captured pictures "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm \n",
    "from random import shuffle \n",
    "import os\n",
    "import cv2\n",
    "def generate_labels(img_name):\n",
    "    name = img_name.split('.')[0]\n",
    "    if name =='Ahmed':\n",
    "        return np.array([1,0])\n",
    "    if name=='User2':\n",
    "        return np.array([0,1])\n",
    "data=[]\n",
    "for img in tqdm(os.listdir(\"pix/data/\")):\n",
    "    path= os.path.join('pix/data/',img)\n",
    "    img_data=cv2.imread(path,cv2.COLOR_BGR2GRAY)\n",
    "    img_data=cv2.resize(img_data,(500,500))\n",
    "    data.append([np.array(img_data),generate_labels(img)])\n",
    "shuffle(data)      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split the data into train and validation samples "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "train=data[:800]\n",
    "test=data[800:]\n",
    "X_train= np.array([i[0] for i in train]).reshape(-1,500,500,1)\n",
    "Y_train= np.array([i[1] for i in train])\n",
    "x_test= np.array([i[0] for i in test]).reshape(-1,500,500,1)\n",
    "y_test= np.array([i[1] for i in test])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# plot the traning sample with labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig=plt.figure(figsize=(35,27))\n",
    "for i in range(100):\n",
    "    \n",
    "    y=fig.add_subplot(10,10,i+1)    \n",
    "    y.imshow(X_train[i].reshape(500,500),cmap=plt.cm.gray,interpolation='nearest');\n",
    "    if Y_train[i][0] == 1:\n",
    "        plt.title('Ahmed',color='r',fontsize=20)\n",
    "    if Y_train[i][0] == 0:\n",
    "        plt.title('User2',color='r',fontsize=20)    \n",
    "    plt.axis(\"off\")    \n",
    "   # plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tflearn \n",
    "from tflearn.layers.conv import conv_2d, max_pool_2d\n",
    "from tflearn.layers.core import input_data, dropout,fully_connected\n",
    "from tflearn.layers.estimator import regression\n",
    "\n",
    "tf.compat.v1.reset_default_graph()\n",
    "convnet=input_data(shape=[500,500,1])\n",
    "convnet=conv_2d(convnet,32,5,activation='relu')\n",
    "convnet=max_pool_2d(convnet,5)\n",
    "convnet=conv_2d(convnet,64,5,activation='relu')\n",
    "convnet=max_pool_2d(convnet,5)\n",
    "convnet=conv_2d(convnet,128,5,activation='relu')\n",
    "convnet=max_pool_2d(convnet,5)\n",
    "convnet=conv_2d(convnet,64,5,activation='relu')\n",
    "convnet=max_pool_2d(convnet,5)\n",
    "convnet=conv_2d(convnet,32,5,activation='relu')\n",
    "convnet=max_pool_2d(convnet,5)\n",
    "\n",
    "convnet=fully_connected(convnet,1024,activation='relu')\n",
    "convnet=dropout(convnet,0.8)\n",
    "convnet=fully_connected(convnet,2,activation='softmax')\n",
    "convnet=regression(convnet,optimizer='adam',learning_rate=0.001,loss='categorical_crossentropy')\n",
    "model=tflearn.DNN(convnet,tensorboard_verbose=1)\n",
    "history =model.fit(X_train,Y_train,n_epoch=5,validation_set=(x_test,y_test),show_metric=True,run_id='FRS')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make predictions with the validation sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig=plt.figure(figsize=(25,17))\n",
    "for i in range(100):\n",
    "    \n",
    "    y=fig.add_subplot(10,10,i+1)    \n",
    "    y.imshow(x_test[i].reshape(500,500),cmap=plt.cm.gray,interpolation='nearest');\n",
    "    if (model.predict([x_test[i]]).flatten()[0])> 0.9:\n",
    "        plt.title('Ahmed',color='r',fontsize=20)\n",
    "    if (model.predict([x_test[i]]).flatten()[0]) < 0.01:\n",
    "        plt.title('User2',color='r',fontsize=20) \n",
    "    \n",
    "    plt.axis('off')   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make prediction with Live camera "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import time \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "face_classifier = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "def face_cropped(img):\n",
    "    gray_img = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    faces_cropped = face_classifier.detectMultiScale(gray_img,1.3,6)\n",
    "    if face_cropped ==():\n",
    "         return None \n",
    "    for (x,y,w,h) in faces_cropped:\n",
    "        cropped_faces = img[y:y+h,x:x+w]\n",
    "        return cropped_faces\n",
    "cap = cv2.VideoCapture(0)\n",
    "while True:\n",
    "    \n",
    "    ret,frame=cap.read()\n",
    "    faces_cropped = face_classifier.detectMultiScale(frame,1.3,6)\n",
    "    for (x,y,w,h) in faces_cropped:\n",
    "        img=cv2.rectangle(frame,(x,y),(x+w,y+h), (0,255,0),2)\n",
    "        face= cv2.resize(img[y:y+h,x:x+w],(500,500))\n",
    "        face=cv2.cvtColor(face,cv2.COLOR_BGR2GRAY)\n",
    "        face=np.array(face).reshape(-1,500,500,1)\n",
    "        \n",
    "        pred=model.predict(face).flatten()[1];\n",
    "        #print(model.predict(face))\n",
    "        if pred > 0.5:\n",
    "            cv2.putText(frame,'Ahmed  '+ '%.2f'%(pred*100)+'%',(x,y-20),cv2.FONT_HERSHEY_SIMPLEX,1,(0,0,255),3)\n",
    "        elif pred < 0.01:\n",
    "            cv2.putText(frame,'User2   '+ '%.0f'%((1-pred)*100)+'%',(x,y-20),cv2.FONT_HERSHEY_SIMPLEX,1,(0,0,255),3)    \n",
    "    cv2.imshow('Frame',frame)\n",
    "    if cv2.waitKey(1)& 0xFF == ord('q'):\n",
    "        break\n",
    "    \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
